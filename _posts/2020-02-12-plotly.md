---
title: "Logistic Regression from Scratch using Python"
date: 2020-02-12
tags: [machine-learning]
header:
    image: "/images/lake-house.jpg"
excerpt: "Create a logistic regression classifier from scratch and compare it to the sklearn version."
mathjax: "true"
---

# Logistic Regression

In statistics, the logistic model (or logit model) is used to model the probability of a certain class or event existing such as pass/fail, win/lose, alive/dead or healthy/sick. This can be extended to model several classes of events such as determining whether an image contains a cat, dog, lion, etc. Each object being detected in the image would be assigned a probability between 0 and 1 and the sum adding to one. In the Machine Learning world, Logistic Regression is a kind of parametric classification model, despite having the word ‘regression’ in its name.
This means that logistic regression models are models that have a certain fixed number of parameters that depend on the number of input features, and they output categorical prediction, like for example if a plant belongs to a certain species or not. To get a better understanding how logistic regression works I can suggest the awesome videos by *Josh Starmer* [Youtube Link to his channel](https://www.youtube.com/user/joshstarmer). As we want to focus on creating a classifier from scratch I will assume the following things:

* You have basic knowledge in python
* You have a basic understanding of how logistic regression works
* You know what backpropagation is

If that is the case, we can finally start:

## Create the dataset

Here we will use a simple dataset which can be created using the `sklearn.dataset.make_blobs` function.

![Logistic Regression dataset](/images/log-regression/data.png)

The picture above shows the two classes of the data which we will try to predict. This dataset can be reproduced by executing the following code:

```python
import numpy as np
import seaborn as sns
import sklearn.datasets as sd

# =============================================================================
# Create a dataset
# =============================================================================

data, labels = sd.make_blobs(5000, 2, 2, cluster_std=2.2, random_state=7) 

# Plot the data
sns.scatterplot(data[:, 0], data[:, 1], hue=labels)
```

After we created our dataset it is time to start writing code for our logistic classifier.

## Logistic classifier

One of the things that really often gets connected to logistic regression is the so called *Sigmoid function*. Basically this function takes an input from -$$\infty$$ to +$$\infty$$ and computes a value between $$0$$ and $$1$$. Important to understand is, that *Sigmoid function* is a wrapper for differetn functions which all produce similar output. In our case we used the *logistic function*. Below you see the function and the value range.

![logistic function](/images/log-regression/sigmoid.png)

The logistic function is defined as $$ h_ \theta (x) =  \frac{\mathrm{1} }{\mathrm{1} + e^- \theta^Tx }  $$, therefore we can simply translate that into python:

```python
def sigmoid(scores):
    return(1 / (1 + np.exp(-scores)))
```
